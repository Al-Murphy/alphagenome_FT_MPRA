_wandb:
    value:
        cli_version: 0.23.1
        e:
            iz0kosdg523wxj7u7asy8fp4dj2nyivq:
                cpu_count: 56
                cpu_count_logical: 112
                cudaVersion: "12.3"
                disk:
                    /:
                        total: "42924244992"
                        used: "31272960000"
                email: alanmurph94@hotmail.com
                executable: /grid/koo/home/amurphy/projects/alphagenome_FT_MPRA/.venv/bin/python
                git:
                    commit: 76514d9375976f7cd22eed01ccbd0a1a857656d9
                    remote: https://github.com/Al-Murphy/alphagenome_FT_MPRA
                gpu: NVIDIA H100 NVL
                gpu_count: 1
                gpu_nvidia:
                    - architecture: Hopper
                      cudaCores: 16896
                      memoryTotal: "100485038080"
                      name: NVIDIA H100 NVL
                      uuid: GPU-eebaafe6-5b77-9f21-3d71-855427ed24bf
                host: bamgpu101
                memory:
                    total: "1081661394944"
                os: Linux-4.18.0-513.18.1.el8_9.x86_64-x86_64-with-glibc2.28
                program: /grid/koo/home/amurphy/projects/alphagenome_FT_MPRA/tmp.py
                python: CPython 3.11.11
                root: /grid/koo/home/amurphy/projects/alphagenome_FT_MPRA
                slurm:
                    cluster_name: slurm
                    conf: /cm/shared/apps/slurm/var/etc/slurm/slurm.conf
                    cpus_on_node: "2"
                    distribution: cyclic
                    gpus_on_node: "1"
                    gtids: "0"
                    job_account: koolab
                    job_cpus_per_node: "2"
                    job_end_time: "1768267968"
                    job_gid: "11096"
                    job_id: "436866"
                    job_name: interactive
                    job_nodelist: bamgpu101
                    job_num_nodes: "1"
                    job_partition: kooq
                    job_qos: koolab
                    job_start_time: "1768224768"
                    job_uid: "11936"
                    job_user: amurphy
                    jobid: "436866"
                    launch_node_ipaddr: 172.20.0.72
                    localid: "0"
                    mem_per_node: "98304"
                    nnodes: "1"
                    nodeid: "0"
                    nodelist: bamgpu101
                    nprocs: "1"
                    ntasks: "1"
                    prio_process: "0"
                    procid: "0"
                    pty_port: "35305"
                    pty_win_col: "187"
                    pty_win_row: "32"
                    srun_comm_host: 172.20.0.72
                    srun_comm_port: "35271"
                    step_gpus: "0"
                    step_id: "0"
                    step_launcher_port: "35271"
                    step_nodelist: bamgpu101
                    step_num_nodes: "1"
                    step_num_tasks: "1"
                    step_tasks_per_node: "1"
                    stepid: "0"
                    submit_dir: /grid/koo/home/amurphy/projects/alphagenome_FT_MPRA
                    submit_host: bamdev4
                    task_pid: "2278567"
                    tasks_per_node: "1"
                    tmpdir: /tmp/slurm_tmp/436866
                    topology_addr: bamgpu101
                    topology_addr_pattern: node
                    umask: "0022"
                startedAt: "2026-01-12T21:57:49.658796Z"
                writerId: iz0kosdg523wxj7u7asy8fp4dj2nyivq
        m: []
        python_version: 3.11.11
        t:
            "1":
                - 2
                - 3
                - 12
                - 45
            "2":
                - 2
                - 3
                - 12
                - 45
            "3":
                - 2
                - 13
                - 16
            "4": 3.11.11
            "5": 0.23.1
            "8":
                - 2
            "12": 0.23.1
            "13": linux-x86_64
gradient_accumulation_steps:
    value: 1
head_name:
    value: mpra_head
learning_rate:
    value: 0.0001
num_epochs:
    value: 3
train_batches:
    value: 31
val_batches:
    value: 4
